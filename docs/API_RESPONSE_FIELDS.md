# üìã Documentation des Champs de R√©ponse des APIs

Ce document r√©pertorie tous les champs disponibles dans les r√©ponses des APIs des diff√©rents fournisseurs d'intelligence artificielle int√©gr√©s dans l'extension AI Developer Analytics.

## üìä Vue d'ensemble

| Fournisseur | Endpoint | Format | Streaming | Mod√®les Support√©s |
|-------------|----------|--------|-----------|-------------------|
| **OpenAI** | `https://api.openai.com/v1/chat/completions` | JSON | ‚úÖ | GPT-4o, GPT-4, GPT-3.5-turbo |
| **Anthropic** | `https://api.anthropic.com/v1/messages` | JSON | ‚úÖ | Claude-3.5-Sonnet, Claude-3-Opus |
| **DeepSeek** | `https://api.deepseek.com/chat/completions` | JSON | ‚úÖ | deepseek-chat, deepseek-coder |
| **Moonshot** | `https://api.moonshot.cn/v1/chat/completions` | JSON | ‚úÖ | moonshot-v1-8k, moonshot-v1-32k, moonshot-v1-128k |
| **Ollama** | `http://localhost:11434/api/generate` | JSON | ‚úÖ | Tous les mod√®les locaux |

---

## üîµ OpenAI API

### Structure de R√©ponse Compl√®te

```json
{
  "id": "chatcmpl-1234567890abcdef",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "R√©ponse de l'assistant IA..."
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 20,
    "total_tokens": 30
  }
}
```

### Champs Disponibles

| Champ | Type | Description | Obligatoire |
|-------|------|-------------|-------------|
| `id` | `string` | Identifiant unique de la r√©ponse | ‚úÖ |
| `object` | `string` | Type d'objet ("chat.completion") | ‚úÖ |
| `created` | `integer` | Timestamp Unix de cr√©ation | ‚úÖ |
| `model` | `string` | Nom du mod√®le utilis√© | ‚úÖ |
| `system_fingerprint` | `string` | Empreinte du syst√®me | ‚ùå |
| `choices` | `array` | Liste des r√©ponses g√©n√©r√©es | ‚úÖ |
| `choices[].index` | `integer` | Index du choix | ‚úÖ |
| `choices[].message` | `object` | Message de l'assistant | ‚úÖ |
| `choices[].message.role` | `string` | R√¥le ("assistant") | ‚úÖ |
| `choices[].message.content` | `string` | Contenu de la r√©ponse | ‚úÖ |
| `choices[].logprobs` | `object\|null` | Probabilit√©s logarithmiques | ‚ùå |
| `choices[].finish_reason` | `string` | Raison d'arr√™t ("stop", "length", "content_filter") | ‚úÖ |
| `usage` | `object` | M√©triques d'utilisation | ‚úÖ |
| `usage.prompt_tokens` | `integer` | Tokens d'entr√©e | ‚úÖ |
| `usage.completion_tokens` | `integer` | Tokens de sortie | ‚úÖ |
| `usage.total_tokens` | `integer` | Total des tokens | ‚úÖ |

---

## üü£ Anthropic API

### Structure de R√©ponse Compl√®te

```json
{
  "id": "msg_01234567890abcdef",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "R√©ponse de Claude..."
    }
  ],
  "model": "claude-3-5-sonnet-20241022",
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 10,
    "output_tokens": 20
  }
}
```

### Champs Disponibles

| Champ | Type | Description | Obligatoire |
|-------|------|-------------|-------------|
| `id` | `string` | Identifiant unique du message | ‚úÖ |
| `type` | `string` | Type de r√©ponse ("message") | ‚úÖ |
| `role` | `string` | R√¥le de l'exp√©diteur ("assistant") | ‚úÖ |
| `content` | `array` | Contenu du message | ‚úÖ |
| `content[].type` | `string` | Type de contenu ("text") | ‚úÖ |
| `content[].text` | `string` | Texte du contenu | ‚úÖ |
| `model` | `string` | Nom du mod√®le utilis√© | ‚úÖ |
| `stop_reason` | `string` | Raison d'arr√™t ("end_turn", "max_tokens", "stop_sequence") | ‚úÖ |
| `stop_sequence` | `string\|null` | S√©quence d'arr√™t | ‚ùå |
| `usage` | `object` | M√©triques d'utilisation | ‚úÖ |
| `usage.input_tokens` | `integer` | Tokens d'entr√©e | ‚úÖ |
| `usage.output_tokens` | `integer` | Tokens de sortie | ‚úÖ |

---

## üî¥ DeepSeek API

### Structure de R√©ponse Compl√®te

```json
{
  "id": "chatcmpl-1234567890abcdef",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "deepseek-chat",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "R√©ponse de DeepSeek..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 20,
    "total_tokens": 30
  }
}
```

### Champs Disponibles

| Champ | Type | Description | Obligatoire |
|-------|------|-------------|-------------|
| `id` | `string` | Identifiant unique de la r√©ponse | ‚úÖ |
| `object` | `string` | Type d'objet ("chat.completion") | ‚úÖ |
| `created` | `integer` | Timestamp Unix de cr√©ation | ‚úÖ |
| `model` | `string` | Nom du mod√®le utilis√© | ‚úÖ |
| `choices` | `array` | Liste des r√©ponses g√©n√©r√©es | ‚úÖ |
| `choices[].index` | `integer` | Index du choix | ‚úÖ |
| `choices[].message` | `object` | Message de l'assistant | ‚úÖ |
| `choices[].message.role` | `string` | R√¥le ("assistant") | ‚úÖ |
| `choices[].message.content` | `string` | Contenu de la r√©ponse | ‚úÖ |
| `choices[].finish_reason` | `string` | Raison d'arr√™t ("stop", "length") | ‚úÖ |
| `usage` | `object` | M√©triques d'utilisation | ‚úÖ |
| `usage.prompt_tokens` | `integer` | Tokens d'entr√©e | ‚úÖ |
| `usage.completion_tokens` | `integer` | Tokens de sortie | ‚úÖ |
| `usage.total_tokens` | `integer` | Total des tokens | ‚úÖ |

---

## üü° Moonshot API

### Structure de R√©ponse Compl√®te

```json
{
  "id": "chatcmpl-1234567890abcdef",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "moonshot-v1-8k",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "R√©ponse de Moonshot..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 20,
    "total_tokens": 30
  }
}
```

### Champs Disponibles

| Champ | Type | Description | Obligatoire |
|-------|------|-------------|-------------|
| `id` | `string` | Identifiant unique de la r√©ponse | ‚úÖ |
| `object` | `string` | Type d'objet ("chat.completion") | ‚úÖ |
| `created` | `integer` | Timestamp Unix de cr√©ation | ‚úÖ |
| `model` | `string` | Nom du mod√®le utilis√© | ‚úÖ |
| `choices` | `array` | Liste des r√©ponses g√©n√©r√©es | ‚úÖ |
| `choices[].index` | `integer` | Index du choix | ‚úÖ |
| `choices[].message` | `object` | Message de l'assistant | ‚úÖ |
| `choices[].message.role` | `string` | R√¥le ("assistant") | ‚úÖ |
| `choices[].message.content` | `string` | Contenu de la r√©ponse | ‚úÖ |
| `choices[].finish_reason` | `string` | Raison d'arr√™t ("stop", "length") | ‚úÖ |
| `usage` | `object` | M√©triques d'utilisation | ‚úÖ |
| `usage.prompt_tokens` | `integer` | Tokens d'entr√©e | ‚úÖ |
| `usage.completion_tokens` | `integer` | Tokens de sortie | ‚úÖ |
| `usage.total_tokens` | `integer` | Total des tokens | ‚úÖ |

---

## üü¢ Ollama API

### Structure de R√©ponse Compl√®te

```json
{
  "model": "phi-4",
  "created_at": "2024-01-01T00:00:00.000Z",
  "response": "R√©ponse d'Ollama...",
  "done": true,
  "context": [1, 2, 3, 4, 5],
  "total_duration": 1000000000,
  "load_duration": 100000000,
  "prompt_eval_count": 10,
  "prompt_eval_duration": 200000000,
  "eval_count": 20,
  "eval_duration": 700000000,
  "prompt_eval_rate": 50.0,
  "eval_rate": 28.57
}
```

### Champs Disponibles

| Champ | Type | Description | Obligatoire |
|-------|------|-------------|-------------|
| `model` | `string` | Nom du mod√®le utilis√© | ‚úÖ |
| `created_at` | `string` | Timestamp ISO de cr√©ation | ‚úÖ |
| `response` | `string` | Contenu de la r√©ponse | ‚úÖ |
| `done` | `boolean` | Indique si la r√©ponse est compl√®te | ‚úÖ |
| `context` | `array` | Contexte pour les requ√™tes suivantes | ‚ùå |
| `total_duration` | `integer` | Dur√©e totale en nanosecondes | ‚ùå |
| `load_duration` | `integer` | Dur√©e de chargement du mod√®le | ‚ùå |
| `prompt_eval_count` | `integer` | Nombre de tokens √©valu√©s dans le prompt | ‚ùå |
| `prompt_eval_duration` | `integer` | Dur√©e d'√©valuation du prompt | ‚ùå |
| `eval_count` | `integer` | Nombre de tokens g√©n√©r√©s | ‚ùå |
| `eval_duration` | `integer` | Dur√©e de g√©n√©ration | ‚ùå |
| `prompt_eval_rate` | `number` | Taux d'√©valuation du prompt (tokens/sec) | ‚ùå |
| `eval_rate` | `number` | Taux de g√©n√©ration (tokens/sec) | ‚ùå |

---

## üîÑ R√©ponses de Streaming

### Format SSE (Server-Sent Events)

Tous les fournisseurs supportent le streaming via SSE. Le format g√©n√©ral est :

```
data: {"id": "chatcmpl-123", "object": "chat.completion.chunk", "created": 1677652288, "model": "gpt-4o", "choices": [{"index": 0, "delta": {"content": "Hello"}, "finish_reason": null}]}

data: {"id": "chatcmpl-123", "object": "chat.completion.chunk", "created": 1677652288, "model": "gpt-4o", "choices": [{"index": 0, "delta": {"content": " world"}, "finish_reason": null}]}

data: [DONE]
```

### Champs Sp√©cifiques au Streaming

| Champ | Type | Description |
|-------|------|-------------|
| `object` | `string` | "chat.completion.chunk" |
| `choices[].delta` | `object` | Changement incr√©mental |
| `choices[].delta.content` | `string` | Nouveau contenu |
| `choices[].delta.role` | `string` | R√¥le (premier chunk) |
| `choices[].finish_reason` | `string\|null` | Raison d'arr√™t (dernier chunk) |

---

## üìà M√©triques et Co√ªts

### Calcul des Co√ªts par Fournisseur

| Fournisseur | Co√ªt Input (per 1K tokens) | Co√ªt Output (per 1K tokens) |
|-------------|----------------------------|------------------------------|
| **OpenAI** | $0.01 | $0.03 |
| **Anthropic** | $0.015 | $0.075 |
| **DeepSeek** | $0.00014 | $0.00028 |
| **Moonshot** | $0.01 | $0.03 |
| **Ollama** | $0.00 | $0.00 (local) |

### Formule de Calcul

```typescript
const inputCost = (inputTokens / 1000) * costPerInputToken;
const outputCost = (outputTokens / 1000) * costPerOutputToken;
const totalCost = inputCost + outputCost;
```

---

## üõ†Ô∏è Utilisation dans l'Extension

### Extraction des Champs Principaux

```typescript
// Exemple d'extraction pour tous les fournisseurs
const extractResponseData = (apiResponse: any, provider: string) => {
  switch (provider) {
    case 'openai':
    case 'deepseek':
    case 'moonshot':
      return {
        content: apiResponse.choices[0].message.content,
        model: apiResponse.model,
        usage: apiResponse.usage,
        id: apiResponse.id
      };
    
    case 'anthropic':
      return {
        content: apiResponse.content[0].text,
        model: apiResponse.model,
        usage: {
          prompt_tokens: apiResponse.usage.input_tokens,
          completion_tokens: apiResponse.usage.output_tokens,
          total_tokens: apiResponse.usage.input_tokens + apiResponse.usage.output_tokens
        },
        id: apiResponse.id
      };
    
    case 'ollama':
      return {
        content: apiResponse.response,
        model: apiResponse.model,
        usage: {
          prompt_tokens: apiResponse.prompt_eval_count || 0,
          completion_tokens: apiResponse.eval_count || 0,
          total_tokens: (apiResponse.prompt_eval_count || 0) + (apiResponse.eval_count || 0)
        },
        id: apiResponse.created_at
      };
  }
};
```

---

## üìù Notes Importantes

1. **Champs Obligatoires** : Tous les champs marqu√©s comme obligatoires (‚úÖ) sont garantis d'√™tre pr√©sents dans les r√©ponses.

2. **Champs Optionnels** : Les champs marqu√©s comme optionnels (‚ùå) peuvent ne pas √™tre pr√©sents selon la configuration ou la version de l'API.

3. **Versions d'API** : Les structures peuvent varier selon les versions d'API. Consultez la documentation officielle pour les derni√®res mises √† jour.

4. **Gestion d'Erreurs** : Toutes les APIs peuvent retourner des erreurs avec des structures diff√©rentes. Impl√©mentez une gestion d'erreur robuste.

5. **Rate Limiting** : Chaque fournisseur a ses propres limites de taux. Consultez leur documentation pour les d√©tails.

---

## üîó Liens Utiles

- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Anthropic API Documentation](https://docs.anthropic.com/claude/reference)
- [DeepSeek API Documentation](https://platform.deepseek.com/api-docs/)
- [Moonshot API Documentation](https://platform.moonshot.ai/docs/guide/start-using-kimi-api)
- [Ollama API Documentation](https://github.com/ollama/ollama/blob/main/docs/api.md)

---

*Derni√®re mise √† jour : Octobre 2024*
*Version de l'extension : 0.3.1*
