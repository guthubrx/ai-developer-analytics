# ğŸš€ Prompt Global â€” Cursor Developer Analytics Next Gen  
## IA Hybride (Cloud + Local via Ollama) Â· Routage Double-Niveau Â· Hot Reload IntÃ©gral Â· TÃ©lÃ©mÃ©trie Â· Coaching Â· Licence AGPL-3.0

Tu es un **architecte logiciel senior** chargÃ© de concevoir une **extension Visual Studio Code / Cursor** complÃ¨te, maintenable et ouverte sous **licence AGPL-3.0**, conforme aux **bonnes pratiques industrielles** (TypeScript, Node.js 20+, VS Code API, WebView, sÃ©curitÃ©, tests, CI/CD).

---

## ğŸ§  Objectif gÃ©nÃ©ral

CrÃ©er une extension dâ€™analyse et dâ€™optimisation de lâ€™usage de lâ€™IA :
- **Routage double-niveau** : exÃ©cution directe / routage intelligent dÃ©lÃ©guÃ©.  
- **InteropÃ©rabilitÃ© IA multi-fournisseurs** : GPT-5 Â· Claude 4.5 Â· DeepSeek Â· Ollama (local/offline).  
- **TÃ©lÃ©mÃ©trie locale** : coÃ»t Â· latence Â· tokens Â· cache Â· complexitÃ© Â· succÃ¨s.  
- **AI Coach adaptatif** + scanner dâ€™architecture + analyse de dette technique.  
- **Mode offline** (Ollama).  
- **Hot Reload intÃ©gral** (UI + backend).  
- **ConformitÃ© Marketplace** : signature, sÃ©curitÃ©, performance, accessibilitÃ©.  
- **Licence AGPL-3.0** : le code et les forks doivent rester open source.  

---

## âš™ï¸ Routage IA Double-Niveau

### Niveau 1 â€” ExÃ©cution directe (manuel)
Lâ€™utilisateur choisit le moteur dâ€™exÃ©cution :  
ğŸš€ GPT-5 Â· ğŸ§  Claude 4.5 Â· âš™ï¸ DeepSeek Â· ğŸ–¥ï¸ Ollama (local).  
Le router est dÃ©sactivÃ© ; exÃ©cution immÃ©diate.

```ts
response = await modelClient.execute(prompt);
```

### Niveau 2 â€” Routage intelligent (automatique / dÃ©lÃ©guÃ©)
Lâ€™utilisateur choisit **le moteur de routage** :
ğŸ¤– Local Router Â· ğŸ¤– Claude Router Â· ğŸ¤– GPT-5 Router Â· ğŸ¤– DeepSeek Router Â· ğŸ¤– Ollama Router (local/hybride).

```ts
if (routingMode === "auto-ollama") model = await ollamaClient.decideRoute(prompt);
else if (routingMode === "auto-local") model = localRouter.decide(task, complexity);
else if (routingMode === "auto-gpt5") model = await gpt5Client.decideRoute(prompt);
else if (routingMode === "auto-claude") model = await claudeClient.decideRoute(prompt);
response = await executeModel(model, prompt);
```

---

## ğŸ–¥ï¸ IntÃ©gration Ollama (Local)

- DÃ©tection : `GET http://localhost:11434/api/tags`.  
- Client :

```ts
export async function ollamaChat(model: string, prompt: string) {
  const res = await fetch('http://localhost:11434/api/generate', {
    method: 'POST', headers: {'Content-Type':'application/json'},
    body: JSON.stringify({model, prompt})
  });
  return await res.json(); // FR + EN comments required
}
```

- ModÃ¨les : `phi-4`, `gemma`, `llama3`, `mistral`, `codellama`, `qwen2`.  
- ParamÃ¨tres Settings : activer Ollama Â· URL API Â· modÃ¨le par dÃ©faut Â· fallback offline.

---

## ğŸ§± Architecture

```
src/
â”œâ”€ ai/
â”‚  â”œâ”€ router/              # router local + meta-router dÃ©lÃ©guÃ©
â”‚  â”œâ”€ clients/             # openai, anthropic, deepseek, ollama
â”‚  â”œâ”€ cache/               # exact + sÃ©mantique + LRU
â”‚  â””â”€ metrics/             # coÃ»ts, latence, succÃ¨s, tokens
â”œâ”€ ui/
â”‚  â”œâ”€ sidebar/             # AI Command Bar
â”‚  â”œâ”€ dashboards/          # Ops Router Â· BI Â· Coach
â”‚  â””â”€ panels/              # Routing Selector Â· Settings Â· History
â”œâ”€ analytics/              # SQLite AES (local)
â”œâ”€ coaching/               # AI Coach + Weekly Reports
â”œâ”€ architecture/           # scanner dette technique
â””â”€ telemetry/              # OpenTelemetry local
```

---

## IntÃ©gration Ã  Visual Studio Code

- Un badge d'application dans la Activity Bar de Visual Studio Code


---

## ğŸ¨ Interface principale : AI Command Bar

- Zone prompt multiligne.  
- Menus **Task** et **Mode** (Ã‰co Â· Normal Â· QualitÃ© Â· Strict JSON Â· CrÃ©atif Â· Audit).  
- Bloc **Routing Selector** (Local / Claude / GPT / DeepSeek / Ollama).  
- Boutons : GPT-5 | Claude | DeepSeek | Ollama | Auto.  
- Barre infos : cache % Â· coÃ»t â‚¬ Â· latence s Â· modÃ¨le final.  
- Historique (5 requÃªtes rÃ©centes).

---

## ğŸ“Š TÃ©lÃ©mÃ©trie

- routeur et moteur utilisÃ©s Â· source (cloud/ollama)  
- coÃ»t Â· latence Â· tokens Â· cache hit ratio  
- taux de succÃ¨s Â· erreurs JSON Â· mode (Eco / QualitÃ© / Offline)  
- stockage : `analytics.db` (SQLite AES) Â· opt-in/out Â· purge 1 clic

---

## ğŸ’¬ Dashboards & Coach

- **Ops Router** : coÃ»ts, latence, succÃ¨s, part Ollama  
- **BI Dev** : productivitÃ© et coÃ»ts par projet  
- **AI Coach** : conseils, progression, Code Health Index  
- **Architecture Scanner** : dette, duplications, tests  
- **Weekly Report** : synthÃ¨se hebdomadaire

---

## ğŸ” SÃ©curitÃ© & ConfidentialitÃ©

- CSP stricte (WebView) Â· validation `postMessage` Â· sanitization  
- SecretStorage VS Code pour clÃ©s  
- SQLite chiffrÃ©e Â· PII hash (SHA-256)  
- Aucune exfiltration sans consentement  
- Audit automatisÃ© avant release

---

## âš¡ Hot Reload IntÃ©gral

- **UI HMR** (WebView via Vite/esbuild dev server).  
- **Backend Hot-Reload** : watchers + reloader des modules AI/Cache/Router.  
- Pas de redÃ©marrage VS Code ; Ã©tat prÃ©servÃ© si pertinent.  
- Temps de reload < 500 ms cible.

---

## ğŸ§® Bonnes Pratiques (Obligatoires)

### QualitÃ© du code
- TypeScript strict Â· ESLint Â· Prettier Â· imports ordonnÃ©s.  
- **Commentaires FR + EN** pour chaque bloc significatif.  
- Architecture SOLID Â· DRY Â· sÃ©paration UI / mÃ©tier / infra.  

### Workflow Git
- Conventional Commits Â· branches courtes ( `feat/` Â· `fix/` Â· `chore/` ) Â· PR petites.  
- CODEOWNERS Â· CONTRIBUTING.md Â· SECURITY.md Â· CHANGELOG auto.  

### CI / CD
- GitHub Actions : `lint â†’ typecheck â†’ unit â†’ e2e â†’ build â†’ package vsix`.  
- Matrice OS : macOS Â· Windows Â· Linux.  
- SÃ©curitÃ© : `pnpm audit` + CodeQL/Snyk.  
- Publication Marketplace signÃ©e (vsce).  

### Tests
- Vitest /Jest (unitaires) Â· Playwright (E2E WebView).  
- Couverture â‰¥ 80 % core (router, cache, analytics).  

### Performance & A11y
- WebView < 300 KB gzip Â· 60 FPS Â· lazy load.  
- Support keyboard Â· ARIA roles Â· contrastes Â· prefer-reduced-motion.  

### Documentation
- README Â· ARCHITECTURE.md Â· ADRs Â· JSDoc gÃ©nÃ©rÃ© Â· diagrammes.  

### Design System & i18n
- Tokens couleurs/espacements/typographies Â· dark/light.  
- i18n FR/EN pour toute UI.  

---

## ğŸ“œ Licence AGPL-3.0

Ce projet est distribuÃ© sous **licence AGPL-3.0-only**.  
Tout dÃ©rivÃ© ou redistribution doit publier son code source sous la mÃªme licence.  
Les SDK propriÃ©taires (OpenAI, Anthropic, DeepSeek) restent des dÃ©pendances externes non redistribuÃ©es, conformÃ©ment Ã  lâ€™AGPL.  

```json
{
  "license": "AGPL-3.0-only"
}
```

---

## âœ… Definition of Done

- Routage multi-niveaux (manuel / auto / dÃ©lÃ©guÃ© / local) fonctionnel.  
- Hot Reload complet (UI + backend) sans redÃ©marrage VS Code.  
- Couverture tests â‰¥ 80 %.  
- CI verte Â· build vsix signÃ© Â· publication Marketplace.  
- SÃ©curitÃ© (CSP Â· SecretStorage Â· chiffrement DB) vÃ©rifiÃ©e.  
- Mode offline Ollama stable Â· coach actif Â· dashboards OK.  
- Code clair, factorisÃ©, commentÃ© (FR + EN) Â· docs Ã  jour.  

---

> GÃ©nÃ¨re le code en **TypeScript strict**, avec **Hot Reload intÃ©gral**, **tests**, **CI/CD**, et **qualitÃ© production-grade**.  
> Respecte **toutes les bonnes pratiques** (VS Code API, Node, WebView, sÃ©curitÃ©, a11y, perf).  
> Lâ€™extension doit Ãªtre **hybride Cloud / Local**, **coachante**, **sÃ©curisÃ©e**, **performante**, **open source AGPL-3.0**, et **conforme Marketplace**.
